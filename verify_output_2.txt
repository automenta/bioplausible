/app/bioplausible/validation/tracks/special_tracks.py:144: SyntaxWarning: invalid escape sequence '\s'
  name="Convolutional EqProp",
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/app/bioplausible/models/transformer_eqprop.py", line 69, in _reshape_output
    out.transpose(1, 2).contiguous().view(batch_size, seq_len, self.hidden_dim)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/app/bioplausible/models/transformer_eqprop.py", line 69, in _reshape_output
    out.transpose(1, 2).contiguous().view(batch_size, seq_len, self.hidden_dim)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/app/bioplausible/models/transformer_eqprop.py", line 69, in _reshape_output
    out.transpose(1, 2).contiguous().view(batch_size, seq_len, self.hidden_dim)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 492, in _power_method
    torch.mv(weight_mat, self._v),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/app/bioplausible/models/transformer_eqprop.py", line 69, in _reshape_output
    out.transpose(1, 2).contiguous().view(batch_size, seq_len, self.hidden_dim)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/app/bioplausible/models/transformer_eqprop.py", line 69, in _reshape_output
    out.transpose(1, 2).contiguous().view(batch_size, seq_len, self.hidden_dim)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/app/bioplausible/models/transformer_eqprop.py", line 69, in _reshape_output
    out.transpose(1, 2).contiguous().view(batch_size, seq_len, self.hidden_dim)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 491, in _power_method
    self._u = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 498, in _power_method
    torch.mv(weight_mat.H, self._u),  # type: ignore[has-type]

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 511, in forward
    self._power_method(weight_mat, self.n_power_iterations)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 497, in _power_method
    self._v = F.normalize(

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 202, in _forward_layer
    return torch.lerp(h, torch.tanh(h_target), self.alpha)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 202, in _forward_layer
    return torch.lerp(h, torch.tanh(h_target), self.alpha)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 39, in forward
    out = torch.matmul(attn, V)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 37, in forward
    scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 519, in forward
    return weight / sigma

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 198, in _forward_layer
    ffn_out = self.ffns[layer_idx](h_norm)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 41, in forward
    return self.W_o(self._reshape_output(out, batch_size, seq_len))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 58, in _compute_qkv
    self.W_v(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 53, in _compute_qkv
    self.W_k(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/transformer_eqprop.py", line 187, in forward_step
    current_h = self._forward_layer(current_h, x_transformed, i)
  File "/app/bioplausible/models/transformer_eqprop.py", line 195, in _forward_layer
    h = h + self.attentions[layer_idx](h_norm)
  File "/app/bioplausible/models/transformer_eqprop.py", line 35, in forward
    Q, K, V = self._compute_qkv(h, batch_size, seq_len)
  File "/app/bioplausible/models/transformer_eqprop.py", line 48, in _compute_qkv
    self.W_q(h)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 407, in get_parametrized
    return parametrization()
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrize.py", line 300, in forward
    x = self[0](self.original)
  File "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py", line 518, in forward
    sigma = torch.vdot(u, torch.mv(weight_mat, v))
Gradient addition node due to multiple use of tensor around:
cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/looped_mlp.py", line 123, in forward_step
    return torch.tanh(x_transformed + self.W_rec(h))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/looped_mlp.py", line 123, in forward_step
    return torch.tanh(x_transformed + self.W_rec(h))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/looped_mlp.py", line 123, in forward_step
    return torch.tanh(x_transformed + self.W_rec(h))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/looped_mlp.py", line 123, in forward_step
    return torch.tanh(x_transformed + self.W_rec(h))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/looped_mlp.py", line 123, in forward_step
    return torch.tanh(x_transformed + self.W_rec(h))

cudagraph partition due to non gpu ops. Found from :
   File "/app/bioplausible/models/looped_mlp.py", line 123, in forward_step
    return torch.tanh(x_transformed + self.W_rec(h))

======================================================================
       TOREQPROP COMPREHENSIVE VERIFICATION SUITE
       Undeniable Evidence for All Research Claims
======================================================================
\n Configuration:
   Seed: 42
   Mode:  Quick
   Evidence:  Smoke Test (mechanics only)
   Epochs: 5
   Samples: 200
   Seeds: 1
   Tracks: 48
======================================================================

============================================================
TRACK 14: Transformer EqProp
============================================================
      Running robustness check (1 seeds)...
  Mean Accuracy: 100.0%  0.0%

 Track 14: Transformer EqProp - PASS (100/100)
   Progress: 1/2 | Elapsed: 75s | ETA: 75s

============================================================
TRACK 22: Golden Reference Harness
============================================================

[22a] Initializing identical weights in PyTorch and NumPy...
[22b] Comparing relaxation step-by-step...
  Step  0: max_diff = 1.79e-07 
  Step  1: max_diff = 2.38e-07 
  Step  2: max_diff = 2.38e-07 
  Step  3: max_diff = 3.28e-07 
  Step  4: max_diff = 1.79e-07 
  Step 28: max_diff = 2.38e-07 
  Step 29: max_diff = 2.38e-07 

[22c] Results:
  Max hidden state difference: 3.28e-07
  Output difference: 2.24e-07
  Tolerance: 1.00e-05

 Track 22: Golden Reference Harness - PASS (100/100)
 Notebook saved to: /app/bioplausible/results/verification_notebook.md

======================================================================
 VERIFICATION COMPLETE
======================================================================
  Total time: 76.9s
 Output: /app/bioplausible/results/verification_notebook.md

 Results: 2/2 tracks passed
